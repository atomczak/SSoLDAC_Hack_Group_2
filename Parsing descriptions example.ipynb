{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843333e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Any, Optional, Dict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from utils import cleaning_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8b906",
   "metadata": {},
   "source": [
    "#### Example IFC class and description\n",
    "* source: https://search-test.bsdd.buildingsmart.org/uri/buildingsmart/ifc-4.3/class/IfcWindow\n",
    "\n",
    "\n",
    "We'll use: \n",
    "* TextBlob (NLTK's implementation of punkttokenizer under the hood) to split into sentences.\n",
    "* SPaR.txt to predict which objects occur, some cleaning on top of this. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3ee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"IfcWindow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9042d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "The window is a building element that is predominately used to provide natural light and fresh air. \n",
    "It includes vertical opening but also horizontal opening such as skylights or light domes. \n",
    "It includes constructions with swinging, pivoting, sliding, or revolving panels and fixed panels. \n",
    "A window consists of a lining and one or several panels. \n",
    "A window can:be a \"free standing\" window, contained in an IfcSpatialElement such as an IfcBuildingStorey. \n",
    "fill an opening, typically in a wall. \n",
    "The window will then have a FillsVoids attribute which uses the IfcRelFillsElement relationship to relate the IfcWindow with the IfcOpeningElement; \n",
    "be part of an element assembly, typically an IfcCurtainWall. \n",
    "The window will then have a Decomposes attribute which uses the the IfcRelAggregates relationship to relate the window with the assembly of elements;\n",
    "There are two main representations for window occurrences:\n",
    "IfcWindow entities that have a 3D rectangle 'Profile' shape representation defined. \n",
    "This profile can then be used to parametrically generate the geometry of a window. \n",
    "If not provided, the profile of the IfcOpeningElement can be used if the window fills an opening. \n",
    "The parameters are specified on the relating IfcWindowType that references IfcWindowLiningProperties and \n",
    "IfcWindowPanelProperties for each panel in the window; \n",
    "IfcWindow entities that are not parametrically generated and have only 'Brep', or 'SurfaceModel' geometry.\n",
    "In addition, an IfcWindow may commonly include a 'FootPrint' representation defining the 2D shape of the window and its swing.\n",
    "the window width and height the window opening direction (by the positive y-axis of the ObjectPlacement)\n",
    "The IfcWindowType specifies parameters which are common to all of its occurrences of IfcWindow:\n",
    "the partitioning type (single panel, double panel, tripel panel, more panels) the operation type \n",
    "(swing, tilt and turn, pivot revolve, fixed casement, etc.) \n",
    "the window panel hinge side (by using two different styles for right and left opening windows) \n",
    "the particular attributes for the lining by the IfcWindowLiningProperties the particular attributes \n",
    "for the panels by the  IfcWindowPanelPropertiesREFERENCE Definition according to ISO 6707-1 Construction \n",
    "for closing a vertical or near vertical opening in a wall or pitched roof that will admit light and \n",
    "may admit fresh air. NOTE The entity IfcWindowStandardCase has been deleted. Use an IfcWindow with \n",
    "a 'Profile' representation instead. The IfcWindow should also have an IfcWindowType with \n",
    "ParameterTakesPrecedence set to 'TRUE'. IFC4 CHANGE The attributes PredefinedType and OperationType are\n",
    "added, the applicable type object has been changed to IfcWindowType. HISTORY New entity in IFC1.0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"abrasion\"\n",
    "description = \"\"\"wearing or grinding away of material by friction; usually caused by sand, gravel, or stones, carried by wind or water\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88a5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253ca52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download SPaR.txt if required\n",
    "from pathlib import Path\n",
    "spartxt_path = Path(\"SPaRtxt/\")\n",
    "if not spartxt_path.exists():\n",
    "    !git clone https://github.com/rubenkruiper/SPaR.txt.git SPaRtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0f547a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kind of convoluted way to import spar.txt as a module from the parent directory\n",
    "# import imp\n",
    "# with open(spartxt_path.joinpath('spar_predictor.py'), 'rb') as fp:\n",
    "#     spar_predictor = imp.load_module(\n",
    "#         'spar_predictor', fp, 'SPaRtxt.spar_predictor.py',\n",
    "#         ('.py', 'rb', imp.PY_SOURCE)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de4319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f58e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys \n",
    "# sys.path.insert(1, 'SPaRtxt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fa94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPaRtxt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889eb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import spar_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309fd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59860e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c98762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# TRAIN/LOAD\n",
    "# - trains a model if needed, otherwise load from archive; \n",
    "# - best F1 on dev/validation in the paper is 80,96 trained on a GPU, CPU will be a bit lower ~77.x I think\n",
    "te = spar_utils.TermExtractor(max_num_cpu_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184a0186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wearing or grinding away of material by friction',\n",
       " 'usually caused by sand, gravel, or stones, carried by wind or water']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use existing split into sentences functionality (uses textblob)\n",
    "sentences = te.split_into_sentences(description)\n",
    "# first 3 sents\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af48746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = te.process_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ce601d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show some random extracted objects\n",
    "# random.sample(objects, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3c6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some basic cleaning  \n",
    "regex_filter = cleaning_utils.RegexFilter()\n",
    "def run_filters(to_be_cleaned):\n",
    "    # some basic cleaning steps\n",
    "    _, regex_cleaned  = regex_filter.run_filter(to_be_cleaned) # _ would be the list of terms removed by our regex filters\n",
    "    basic_cleaned = cleaning_utils.custom_cleaning_rules(regex_cleaned)\n",
    "    determiners_removed = [cleaning_utils.remove_determiners(t) for t in basic_cleaned]\n",
    "    cleaned_terms = [t for t in determiners_removed if t]\n",
    "    cleaned_counter = Counter(cleaned_terms)\n",
    "    \n",
    "    # Could compare how often the objects occur in all extracted descriptions\n",
    "    cleaned_terms = [t for t in cleaned_terms if cleaned_counter[t] >= 1]\n",
    "    cleaned_counter = Counter({t: c for t, c in cleaned_counter.items() if c >= 1})\n",
    "    return cleaned_terms, cleaned_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ecc303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('material', 1),\n",
       " ('friction', 1),\n",
       " ('sand', 1),\n",
       " ('gravel', 1),\n",
       " ('stones', 1),\n",
       " ('wind', 1),\n",
       " ('water', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, obj_cntr = run_filters(objects)\n",
    "obj_cntr.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cd10d",
   "metadata": {},
   "source": [
    "### Search for object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936e6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = \"https://test.bsdd.buildingsmart.org/api/ClassificationSearchOpen/v1?SearchText=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1879c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240d16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(url_prefix + urllib.parse.quote(query)).json()\n",
    "except: # todo: catch more elegantly\n",
    "    print(\"Search terms doesn't exist\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b679453b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'https://tools.ietf.org/html/rfc7231#section-6.5.1',\n",
       " 'title': 'One or more validation errors occurred.',\n",
       " 'status': 400,\n",
       " 'traceId': '00-8f31c869282987074e4e52fc456e2c27-1a6421f0e85d5acc-00',\n",
       " 'errors': {'SearchText': ['The SearchText field is required.']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caa6f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_string_exists_as_bsdd_label(\n",
    "    query: str,\n",
    "    url_prefix: str = \"https://test.bsdd.buildingsmart.org/api/ClassificationSearchOpen/v1?SearchText=\"\n",
    "):\n",
    "    try:\n",
    "        response = requests.get(url_prefix + urllib.parse.quote(query)).json()\n",
    "        return response\n",
    "    except:\n",
    "        # no search results\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b202cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bsdd_api_response(json_response: Dict[str,str]):    \n",
    "    search_results = []\n",
    "    for result in json_response['classifications']:\n",
    "        domain_namespace = result['domainNamespaceUri']\n",
    "\n",
    "#         # LIMIT RESULTS TO IFC 4.3 for now \n",
    "#         if not str(domain_namespace).endswith(\"ifc-4.3\"):\n",
    "#             continue\n",
    "\n",
    "        domain_name = result['domainName']\n",
    "        name = result['name']\n",
    "        reference_code = result['referenceCode'] if 'referenceCode' in result else None\n",
    "        namespace_uri = result['namespaceUri'] if 'namespaceUri' in result else None\n",
    "        description = result['description'] if 'description' in result else None\n",
    "        parent_name = result['parentClassificationName'] if 'parentClassificationName' in result else None\n",
    "        related_ifc_entity_names = result['relatedIfcEntityNames'] if 'relatedIfcEntityNames' in result else None\n",
    "        \n",
    "        results_of_interest = {\"name\": name, \"description\": description, \"related\": related_ifc_entity_names}\n",
    "        search_results.append(results_of_interest)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b07a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0127ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = \"IfcWindow\"\n",
    "# objects as extracted from the definition for \"IfcWindow\"\n",
    "def suggest(label: str, obj_cntr: Counter):\n",
    "    useless_objs = [\"entity\", \"HISTORY\"]\n",
    "    top_k = 5\n",
    "\n",
    "    suggested_rel_dict = {label: {}}\n",
    "    terms_with_overlap_in_description_objects = {}\n",
    "    for obj, count in tqdm(obj_cntr.most_common()):\n",
    "\n",
    "        if obj in useless_objs or obj in label:\n",
    "            continue\n",
    "\n",
    "        # 1) search for bsdd nodes with the object span as the query\n",
    "        bsdd_response = check_if_string_exists_as_bsdd_label(obj)\n",
    "        if bsdd_response:\n",
    "            bsdd_results = parse_bsdd_api_response(bsdd_response)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if top_k:\n",
    "            # only look at top_k results from bsdd search\n",
    "            bsdd_results = bsdd_results[:top_k]\n",
    "\n",
    "        # 2) Compare if the retrieved, potentially related nodes, contain the same object in their description\n",
    "        \n",
    "        for result_dict in bsdd_results:\n",
    "            name = result_dict[\"name\"] if \"name\" in result_dict else None\n",
    "            bsdd_description = result_dict[\"description\"] if \"description\" in result_dict else None\n",
    "            if not bsdd_description:\n",
    "                continue \n",
    "\n",
    "            if obj in bsdd_description:\n",
    "                if name not in terms_with_overlap_in_description_objects:\n",
    "                    terms_with_overlap_in_description_objects[name] = [obj]\n",
    "                else:\n",
    "                    terms_with_overlap_in_description_objects[name].append(obj)\n",
    "                    \n",
    "\n",
    "    # 3) Collect suggestions of related terms\n",
    "    for potentially_related, matching_objects in terms_with_overlap_in_description_objects.items():\n",
    "#         if label == potentially_related or label.startswith(potentially_related) or potentially_related.startswith(label):\n",
    "#             # we assume that if the original label occurs in the search results for a span, they are too close\n",
    "# #             print(f\"Skipping self: {label} found when searching for {obj}\")\n",
    "#             continue\n",
    "    \n",
    "        if len(matching_objects) < 2:\n",
    "            continue\n",
    "\n",
    "        if potentially_related not in suggested_rel_dict[label]:\n",
    "            suggested_rel_dict[label][potentially_related] = matching_objects\n",
    "        else:\n",
    "            suggested_rel_dict[label][potentially_related] += matching_objects\n",
    "    return suggested_rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7a985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spartxt_ner(long_description: str):\n",
    "    # use existing split into sentences functionality (uses textblob)\n",
    "    sentences = te.split_into_sentences(long_description)\n",
    "    objects = te.process_sentences(sentences)\n",
    "    _, object_counter = run_filters(objects)\n",
    "    return object_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d28a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"abrasion\"\n",
    "description = \"\"\"\n",
    "Wearing or grinding away of material by friction; usually caused by sand, gravel, or stones, carried by wind or water.\n",
    "1) Loss of section or coating of a culvert by the mechanical action of water conveying suspended bed load of sand, gravel, and cobble-size particles at high velocities with appreciable turbulence. 2) Removal of stream bank material due to entrained sediment, ice, or debris rubbing against the bank.\n",
    "Loss of section or coating of a culvert by the mechanical action of water conveying suspended bed load of sand, gravel, and cobble-size particles at high velocities with appreciable turbulence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f33c7bfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: abrasion \n",
      "Definition: \n",
      "Wearing or grinding away of material by friction; usually caused by sand, gravel, or stones, carried by wind or water.\n",
      "1) Loss of section or coating of a culvert by the mechanical action of water conveying suspended bed load of sand, gravel, and cobble-size particles at high velocities with appreciable turbulence. 2) Removal of stream bank material due to entrained sediment, ice, or debris rubbing against the bank.\n",
      "Loss of section or coating of a culvert by the mechanical action of water conveying suspended bed load of sand, gravel, and cobble-size particles at high velocities with appreciable turbulence.\n",
      "\n",
      "[('sand', 3), ('gravel', 3), ('water', 2), ('Loss section', 2), ('coating', 2), ('culvert', 2), ('mechanical action', 2), ('suspended bed load', 2), ('cobble size', 2), ('particles', 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 23/23 [00:07<00:00,  2.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'abrasion': {}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Term: {label} \\nDefinition: {description}\")\n",
    "object_counter = spartxt_ner(description)\n",
    "print(object_counter.most_common(10))\n",
    "suggest(label, object_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44825b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"IfcWindow\"\n",
    "description = \"\"\"\n",
    "The window is a building element that is predominately used to provide natural light and fresh air.  It includes vertical opening but also horizontal opening such as skylights or light domes.  It includes constructions with swinging, pivoting, sliding, or revolving panels and fixed panels.  A window consists of a lining and one or several panels.  A window can:be a \"free standing\" window, contained in an IfcSpatialElement such as an IfcBuildingStorey.  fill an opening, typically in a wall.  The window will then have a FillsVoids attribute which uses the IfcRelFillsElement relationship to relate the IfcWindow with the IfcOpeningElement;  be part of an element assembly, typically an IfcCurtainWall.  The window will then have a Decomposes attribute which uses the the IfcRelAggregates relationship to relate the window with the assembly of elements; There are two main representations for window occurrences: IfcWindow entities that have a 3D rectangle 'Profile' shape representation defined.  This profile can then be used to parametrically generate the geometry of a window.  If not provided, the profile of the IfcOpeningElement can be used if the window fills an opening.  The parameters are specified on the relating IfcWindowType that references IfcWindowLiningProperties and  IfcWindowPanelProperties for each panel in the window;  IfcWindow entities that are not parametrically generated and have only 'Brep', or 'SurfaceModel' geometry. In addition, an IfcWindow may commonly include a 'FootPrint' representation defining the 2D shape of the window and its swing. the window width and height the window opening direction (by the positive y-axis of the ObjectPlacement) The IfcWindowType specifies parameters which are common to all of its occurrences of IfcWindow: the partitioning type (single panel, double panel, tripel panel, more panels) the operation type  (swing, tilt and turn, pivot revolve, fixed casement, etc.)  the window panel hinge side (by using two different styles for right and left opening windows)  the particular attributes for the lining by the IfcWindowLiningProperties the particular attributes  for the panels by the  IfcWindowPanelPropertiesREFERENCE Definition according to ISO 6707-1 Construction  for closing a vertical or near vertical opening in a wall or pitched roof that will admit light and  may admit fresh air. NOTE The entity IfcWindowStandardCase has been deleted. Use an IfcWindow with  a 'Profile' representation instead. The IfcWindow should also have an IfcWindowType with  ParameterTakesPrecedence set to 'TRUE'. IFC4 CHANGE The attributes PredefinedType and OperationType are added, the applicable type object has been changed to IfcWindowType. HISTORY New entity in IFC1.0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d96ae4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: IfcWindow \n",
      "Definition: \n",
      "The window is a building element that is predominately used to provide natural light and fresh air.  It includes vertical opening but also horizontal opening such as skylights or light domes.  It includes constructions with swinging, pivoting, sliding, or revolving panels and fixed panels.  A window consists of a lining and one or several panels.  A window can:be a \"free standing\" window, contained in an IfcSpatialElement such as an IfcBuildingStorey.  fill an opening, typically in a wall.  The window will then have a FillsVoids attribute which uses the IfcRelFillsElement relationship to relate the IfcWindow with the IfcOpeningElement;  be part of an element assembly, typically an IfcCurtainWall.  The window will then have a Decomposes attribute which uses the the IfcRelAggregates relationship to relate the window with the assembly of elements; There are two main representations for window occurrences: IfcWindow entities that have a 3D rectangle 'Profile' shape representation defined.  This profile can then be used to parametrically generate the geometry of a window.  If not provided, the profile of the IfcOpeningElement can be used if the window fills an opening.  The parameters are specified on the relating IfcWindowType that references IfcWindowLiningProperties and  IfcWindowPanelProperties for each panel in the window;  IfcWindow entities that are not parametrically generated and have only 'Brep', or 'SurfaceModel' geometry. In addition, an IfcWindow may commonly include a 'FootPrint' representation defining the 2D shape of the window and its swing. the window width and height the window opening direction (by the positive y-axis of the ObjectPlacement) The IfcWindowType specifies parameters which are common to all of its occurrences of IfcWindow: the partitioning type (single panel, double panel, tripel panel, more panels) the operation type  (swing, tilt and turn, pivot revolve, fixed casement, etc.)  the window panel hinge side (by using two different styles for right and left opening windows)  the particular attributes for the lining by the IfcWindowLiningProperties the particular attributes  for the panels by the  IfcWindowPanelPropertiesREFERENCE Definition according to ISO 6707-1 Construction  for closing a vertical or near vertical opening in a wall or pitched roof that will admit light and  may admit fresh air. NOTE The entity IfcWindowStandardCase has been deleted. Use an IfcWindow with  a 'Profile' representation instead. The IfcWindow should also have an IfcWindowType with  ParameterTakesPrecedence set to 'TRUE'. IFC4 CHANGE The attributes PredefinedType and OperationType are added, the applicable type object has been changed to IfcWindowType. HISTORY New entity in IFC1.0.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:28<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Term: {label} \\nDefinition: {description}\")\n",
    "object_counter = spartxt_ner(description)\n",
    "suggested_rel_dict = suggest(label, object_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb2fbd",
   "metadata": {},
   "source": [
    "**Alternative heuristics**:\n",
    "* KNN graph / k nearest neighbours based on embeddings\n",
    "* consider combining label with objects in defintion for a representantion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecc9bd4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'suggested_rel_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[43msuggested_rel_dict\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'suggested_rel_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(suggested_rel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20db642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cf52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4e26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_be_parsed = pd.read_csv(\"bsdd_descriptions.csv\")\n",
    "to_be_parsed = pd.read_csv(\"bsdd_parsed_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aca2405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Location track number or name as an abbreviation \n",
       "1        E.g. additional information related to install...\n",
       "2        Height of the post in millimeters if sign has ...\n",
       "3                       Installation direction of the sign\n",
       "4          The route number on which the object is located\n",
       "                               ...                        \n",
       "28163    Angir hvilket år vegobjektet ble etablert på s...\n",
       "28164             Angir hvilket år utstyret ble produsert.\n",
       "28165         Angir hvilken type energikilde som benyttes.\n",
       "28166             Angir hovedbruksområde for styreapparat.\n",
       "28167                             Angir type styreapparat.\n",
       "Name: description, Length: 28168, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_be_parsed.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d148de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                                   | 94/28168 [00:06<31:24, 14.90it/s]"
     ]
    }
   ],
   "source": [
    "# objects_found = []\n",
    "objects_and_counts = []\n",
    "for description in tqdm(to_be_parsed.description):\n",
    "    try:\n",
    "        object_counter = spartxt_ner(description)\n",
    "        objects_and_counts.append(object_counter.most_common())\n",
    "#         objects = [o for o, _ in object_counter.most_common()]\n",
    "#         objects_found.append(objects)\n",
    "    except:\n",
    "        objects_and_counts.append({})\n",
    "#         objects_found.append(\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7f0f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'objects_and_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# to_be_parsed['objects_found'] = objects_found\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m to_be_parsed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjects_and_counts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_and_counts\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'objects_and_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# to_be_parsed['objects_found'] = objects_found\n",
    "to_be_parsed['objects_and_counts'] = objects_and_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_parsed.to_csv(\"bsdd_parsed_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d18d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_objects(string_list):\n",
    "    span_list = []\n",
    "    for p1 in string_list.split(\"('\")[1:]:\n",
    "        p2 = p1.split(\"',\", 1)[0]\n",
    "        span_list.append(p2)\n",
    "    return span_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745a4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shitty quick solution from already parsed csv (out of time)\n",
    "all_objects = []\n",
    "for string_list in to_be_parsed.objects_and_counts:\n",
    "    all_objects += parse_objects(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d472c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_objects = [o for sublist in to_be_parsed[\"objects_and_counts\"] for o in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4d2a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113448"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77bb4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Location track number',\n",
       " 'name',\n",
       " 'information',\n",
       " 'installation',\n",
       " 'Height',\n",
       " 'post',\n",
       " 'millimeters',\n",
       " 'sign',\n",
       " 'Installation direction',\n",
       " 'sign',\n",
       " 'route number',\n",
       " 'object',\n",
       " 'operating centre',\n",
       " 'object',\n",
       " 'Article number',\n",
       " 'reference',\n",
       " 'configured product',\n",
       " 'standard scheme',\n",
       " 'article number definition',\n",
       " 'manufacturer',\n",
       " 'used',\n",
       " 'purchasing number',\n",
       " 'coordinates',\n",
       " 'object',\n",
       " 'Accessories',\n",
       " 'fasten',\n",
       " 'sign',\n",
       " 'structure',\n",
       " 'object',\n",
       " 'sign',\n",
       " 'maintenance district',\n",
       " 'object',\n",
       " 'signal',\n",
       " 'sign',\n",
       " 'Name',\n",
       " 'sign',\n",
       " 'RATO',\n",
       " 'maintenance oversight district',\n",
       " 'object',\n",
       " 'name',\n",
       " 'Type of foundation',\n",
       " 'sign',\n",
       " 'Installation height',\n",
       " 'sign',\n",
       " 'Owner',\n",
       " 'object asset',\n",
       " 'year production',\n",
       " 'manufactured',\n",
       " 'item',\n",
       " 'Date on',\n",
       " 'element',\n",
       " 'Installation distance',\n",
       " 'sign',\n",
       " 'sign',\n",
       " 'ascending',\n",
       " 'descending direction',\n",
       " 'track',\n",
       " 'route number',\n",
       " 'obecjt',\n",
       " 'time duration',\n",
       " 'manufacturer',\n",
       " 'supplier',\n",
       " 'performance',\n",
       " 'artefact',\n",
       " 'sign',\n",
       " 'Number fasteners',\n",
       " 'fasten',\n",
       " 'Location',\n",
       " 'track line',\n",
       " 'kilometers',\n",
       " 'meters',\n",
       " 'status',\n",
       " 'permit',\n",
       " 'sign',\n",
       " 'face',\n",
       " 'text',\n",
       " 'faces',\n",
       " 'item',\n",
       " 'identifier',\n",
       " 'entire software world',\n",
       " 'object',\n",
       " 'rail line',\n",
       " 'traffic operation',\n",
       " 'organization',\n",
       " 'item',\n",
       " 'type asset',\n",
       " 'object',\n",
       " 'Rail signs',\n",
       " 'Location',\n",
       " 'track line',\n",
       " 'accurate',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'turnout heater',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'Indicate',\n",
       " 'sleeper type',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'Type',\n",
       " 'turnout',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'Maximum speed',\n",
       " 'diverging line',\n",
       " 'type turnout',\n",
       " 'design constraints',\n",
       " 'Condition',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'English description',\n",
       " 'Kiskon valmistaja',\n",
       " 'Kohteen pituus',\n",
       " 'Kiskon teräslaatu , esim',\n",
       " 'tai ei tiedossa',\n",
       " 'Onko suojakiskolla',\n",
       " 'lisäsuojakiskot : kyllä',\n",
       " 'Kohteen valmistusvuosi',\n",
       " 'Suojakis',\n",
       " 'tyypp',\n",
       " 'Kohteen valssausnum',\n",
       " 'Suojakiskon kiinnitys pölkky',\n",
       " 'Tieto siitä millä puolella raidetta kisko sijaitsee',\n",
       " 'Kiskoprofiili , esim',\n",
       " 'E1 tai ei tied',\n",
       " 'property description',\n",
       " 'Tieto siitä onko jatkos sidekiskojatkos',\n",
       " 'Tieto siitä onko sidekiskojatkoksen ja kiskon',\n",
       " 'välille asennettu sähköä johtavat johtimet',\n",
       " 'Kohteen',\n",
       " 'rakenteen tai laitteen valmistajatieto',\n",
       " 'Tiet kohteen , rakenteen tai laitteen sijainnista kiskossa : KM - paalu ja kisko , esim',\n",
       " 'Kohteen',\n",
       " 'laitteen tai rakenteen tyyppiti',\n",
       " 'Kohteen sijainti ratakilometrillä',\n",
       " 'Liikennepaikka tai liikennepaikkaväli jolla kohde sijaitsee',\n",
       " 'Sijaintiraide jolla kohde sijaitsee',\n",
       " 'Omaisuuslaji johon kohde kuuluu',\n",
       " 'Kohteeseen liittyvät mahdolliset lisätiedot',\n",
       " 'Tieto kohteen tietomalliin liittyvästä , esim',\n",
       " 'kohteen rakentamisen kannalta oleellisesta dokumentaatiosta kuten suunnitelmapiirustuksesta',\n",
       " 'Kohteen / rakenteen',\n",
       " 'arvioitu käyttööottopäivä',\n",
       " 'Kohteen koordinaatit objektin insertiopisteest',\n",
       " 'Kohteen yksilöivä tunnus',\n",
       " 'Tieto siitä ,',\n",
       " 'sijaitseeko kohde pää - vai sivuraiteella',\n",
       " 'Kohteen tila',\n",
       " 'Raiteen yksilöivä numero',\n",
       " 'Tieto missä hankevaiheessa kohteen tietomalli on laadittu ja luovutettu',\n",
       " 'Ratanumero jolla kohde sijaitsee',\n",
       " 'Kohteen omist',\n",
       " 'Kohteen ni',\n",
       " 'Kohteen',\n",
       " 'rakenteen tai laitteen kiinnity',\n",
       " 'Pohjaimen jäykky',\n",
       " 'Kohteen , rakenteen tai laitteen materiaali',\n",
       " 'Tieto sijaitseeko kisko kaarella',\n",
       " 'suoralla vai siirtymäkaarella',\n",
       " 'property description',\n",
       " 'Tieto onko kisko uusi vai kierrätetty',\n",
       " 'RATO 11 : n mukainen pölkkyjako',\n",
       " 'Tieto siitä onko puupölkky kyllästetty vai ei',\n",
       " 'Betonipölkyn tyyppi , esim',\n",
       " 'Puupölkyn kyllästysaine , esim',\n",
       " 'Tieto siitä onko pölkyssä',\n",
       " 'pohjain',\n",
       " 'Kohteen , rakenteen tai laitteen asennusvuosi',\n",
       " 'Puupölkyn luokka : esim',\n",
       " 'tai ei tied',\n",
       " 'property description',\n",
       " 'Puupölkyn tyyppi , esim',\n",
       " 'Sileä',\n",
       " 'lovettu',\n",
       " 'porattu',\n",
       " 'KM - paalu jolta nauhamainen',\n",
       " 'viivamainen kohde tai rakenne alkaa',\n",
       " 'Kohteen malliti',\n",
       " 'Tieto siitä toimiiko ankkuri vaellusankkurina : kyllä , ei',\n",
       " 'KM - paalu jolla nauhamainen',\n",
       " 'viivamainen kohde tai rakenne loppuu',\n",
       " 'Ankkureiden jako , esim',\n",
       " 'x kpl',\n",
       " 'ankkureita y määrällä pölkkyjä , esim',\n",
       " 'ankkuria 20 pölkyllä',\n",
       " 'Onko eristysjatkoksessa kestomagneetti',\n",
       " 'property description',\n",
       " 'Eristysjatkoksen tyyppi , esim',\n",
       " 'MT',\n",
       " 'MT - K43 jne',\n",
       " 'suunta , mihin on huomattavasti enemmän liikennettä tai',\n",
       " 'akselipaino on huomattavasti raskaampi',\n",
       " 'Arvona kilometripaalutuksen nouseva',\n",
       " 'laskeva suunta',\n",
       " 'Tieto siitä ,',\n",
       " 'sijaitseeko kohde jatkuvakiskoraiteella',\n",
       " 'Eristysjatkoksen käyttötarkoitus',\n",
       " 'RATO 8 : n mukainen kiskonliikuntalaitteen liikevara',\n",
       " 'Kohteen , rakenteen tai laitteiden vaatimien kiskoankkurien sijainti',\n",
       " 'RATO 8 : n mukainen liikuntasauman kokonaisliike',\n",
       " 'Kiskoliikuntalaitteen liikepituus',\n",
       " 'Laitteen sarjanumero',\n",
       " 'Tieto siitä millä sillalla',\n",
       " 'laite sijaitsee',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'set / valid - oid',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Liikennemerkin',\n",
       " 'taulun',\n",
       " 'materiaali',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'Lisätieto ,',\n",
       " 'viittaus dokumenttiin',\n",
       " 'rakeisuuskäyrä',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'property description 93',\n",
       " 'Ei kuvausta',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'New property description',\n",
       " 'property description',\n",
       " 'Ei kuvausta',\n",
       " 'New property description',\n",
       " 'Ei kuvausta',\n",
       " 'national bridge elements',\n",
       " 'time interval',\n",
       " 'item state',\n",
       " 'corrective maintenance time',\n",
       " 'repair',\n",
       " 'item',\n",
       " 'time interval',\n",
       " 'item',\n",
       " 'down state',\n",
       " 'Operating time',\n",
       " 'first use',\n",
       " 'restoration',\n",
       " 'failure',\n",
       " 'time interval',\n",
       " 'item',\n",
       " 'up state',\n",
       " 'time interval',\n",
       " 'item',\n",
       " 'operating',\n",
       " 'maintenance time',\n",
       " 'active maintenance item',\n",
       " 'Operating time',\n",
       " 'failures',\n",
       " 'status',\n",
       " 'pump',\n",
       " 'obsolete',\n",
       " 'Inability',\n",
       " 'item',\n",
       " 'unavailability',\n",
       " 'market',\n",
       " 'resources',\n",
       " 'acceptable technical',\n",
       " 'economic conditions',\n",
       " 'Average',\n",
       " 'repair',\n",
       " 'Average',\n",
       " 'operating times',\n",
       " 'failures',\n",
       " 'Average',\n",
       " 'time',\n",
       " 'restauration',\n",
       " 'Time interval',\n",
       " 'maintenance',\n",
       " 'item',\n",
       " 'technical',\n",
       " 'logistic delays',\n",
       " 'Time interval',\n",
       " 'instant failure',\n",
       " 'restoration',\n",
       " 'Maintenance task categorization',\n",
       " 'complexity',\n",
       " 'time interval',\n",
       " 'item',\n",
       " 'idle state',\n",
       " 'Duration failures',\n",
       " 'population',\n",
       " 'Number of failures',\n",
       " 'number',\n",
       " 'life units',\n",
       " 'Current state',\n",
       " 'time interval',\n",
       " 'item disabled',\n",
       " 'state',\n",
       " 'property',\n",
       " 'value',\n",
       " 'discrete input unit',\n",
       " 'property',\n",
       " 'status',\n",
       " 'element',\n",
       " 'property',\n",
       " 'number',\n",
       " 'transitions',\n",
       " 'value',\n",
       " 'Off',\n",
       " 'On state',\n",
       " 'Head',\n",
       " 'outlet area',\n",
       " 'pump',\n",
       " 'height',\n",
       " 'pressure head',\n",
       " 'velocity head',\n",
       " 'Outlet pressure',\n",
       " 'pump',\n",
       " 'guarantee point',\n",
       " 'rated flow',\n",
       " 'rated speed',\n",
       " 'rated inlet pressure',\n",
       " 'rotodynamic pumps',\n",
       " 'Rated flow',\n",
       " 'pump outlet connection',\n",
       " 'inlet area',\n",
       " 'pump',\n",
       " 'Height',\n",
       " 'center',\n",
       " 'outlet connection',\n",
       " 'pump',\n",
       " 'alphanumeric designation',\n",
       " 'size',\n",
       " 'components',\n",
       " 'pipework system',\n",
       " 'reference purposes',\n",
       " 'letters',\n",
       " 'dimension',\n",
       " 'whole number',\n",
       " 'physical size',\n",
       " 'millimeters',\n",
       " 'bore outside diameter',\n",
       " 'end connections',\n",
       " 'fluid temperature',\n",
       " 'operating conditions',\n",
       " 'rate of flow',\n",
       " 'operating conditions',\n",
       " 'Fluid',\n",
       " 'pump',\n",
       " 'operating conditions',\n",
       " 'Height',\n",
       " 'center pump',\n",
       " 'Highest relative humidity',\n",
       " 'normal circumstances',\n",
       " 'Temperature',\n",
       " 'application',\n",
       " 'fluid',\n",
       " 'head developed',\n",
       " 'rate of flow',\n",
       " 'final pressure',\n",
       " 'gases',\n",
       " 'ultimate pressure',\n",
       " 'value',\n",
       " 'pressure',\n",
       " 'standardized test dome',\n",
       " 'mptotic',\n",
       " 'normal operation',\n",
       " 'vacuum pump',\n",
       " 'without gas inlet',\n",
       " 'vapors',\n",
       " 'Time interval',\n",
       " 'item',\n",
       " 'up state',\n",
       " 'pump',\n",
       " 'single',\n",
       " 'series connection',\n",
       " 'horizontal plane',\n",
       " 'datum',\n",
       " 'height',\n",
       " 'change',\n",
       " 'status',\n",
       " 'possibility',\n",
       " 'multi - phase - fluid',\n",
       " 'substances',\n",
       " 'solid',\n",
       " 'gaseous states',\n",
       " 'deliberate addition',\n",
       " 'state',\n",
       " 'conditions',\n",
       " 'Average',\n",
       " 'times',\n",
       " 'failures',\n",
       " 'liquid',\n",
       " 'Proportion',\n",
       " 'gaseous substance',\n",
       " 'contaminant',\n",
       " 'vapor',\n",
       " 'main body',\n",
       " 'Categories',\n",
       " 'explosion zones',\n",
       " 'devices',\n",
       " 'to 2014 / 34 / EU',\n",
       " 'ATEX',\n",
       " 'ambient temperature',\n",
       " 'normal',\n",
       " 'Height',\n",
       " 'fluid level',\n",
       " 'inlet side',\n",
       " 'installation',\n",
       " 'center',\n",
       " 'inlet',\n",
       " 'inlet pressure',\n",
       " 'pump operation',\n",
       " 'Proportion',\n",
       " 'solids',\n",
       " 'fluid',\n",
       " 'contaminant',\n",
       " 'useful burden',\n",
       " 'suspension',\n",
       " 'Greatest rate of flow',\n",
       " 'operating conditions',\n",
       " 'control mode',\n",
       " 'use case',\n",
       " 'Inlet pressure',\n",
       " 'installation conditions',\n",
       " 'Rate of flow',\n",
       " 'usual operation',\n",
       " 'Total pressure',\n",
       " 'velocity pressure',\n",
       " 'pump inlet connection',\n",
       " 'liquid vapor pressure',\n",
       " 'present temperature',\n",
       " 'liquid',\n",
       " 'total head developed',\n",
       " 'relative humidity',\n",
       " 'normal circumstances',\n",
       " 'inlet pressure',\n",
       " 'operation',\n",
       " 'pump',\n",
       " 'ambient temperature',\n",
       " 'normal',\n",
       " 'Selected fieldbus',\n",
       " 'product',\n",
       " 'Height',\n",
       " 'fluid level',\n",
       " 'outlet side',\n",
       " 'installation',\n",
       " 'center',\n",
       " 'outlet',\n",
       " 'Maximum possible pressure',\n",
       " 'outlet',\n",
       " 'either',\n",
       " 'internal energy increase',\n",
       " 'rotodynamic pumps',\n",
       " 'external downstream restrictions',\n",
       " 'volumetric pumps',\n",
       " 'Ratio',\n",
       " 'backing pressure',\n",
       " 'inlet pressure',\n",
       " 'vacuum pump',\n",
       " 'throughput',\n",
       " 'Amount',\n",
       " 'fluid',\n",
       " 'Horizontal plane',\n",
       " 'center',\n",
       " 'circle',\n",
       " 'external points',\n",
       " 'entrance edges',\n",
       " 'impeller blades',\n",
       " 'first stage',\n",
       " 'case',\n",
       " 'multi - stage',\n",
       " 'total head',\n",
       " 'pump unit',\n",
       " 'Difference',\n",
       " 'outlet side',\n",
       " 'inlet side',\n",
       " 'usual operation',\n",
       " 'fluid temperature',\n",
       " 'operating conditions',\n",
       " 'outlet pressure',\n",
       " 'operation',\n",
       " 'pump',\n",
       " 'property',\n",
       " 'user value',\n",
       " 'Fault action property',\n",
       " 'property',\n",
       " 'action',\n",
       " 'variables',\n",
       " 'fault state',\n",
       " 'property',\n",
       " 'value',\n",
       " 'discrete output unit',\n",
       " 'pump kick',\n",
       " 'property',\n",
       " 'interval time',\n",
       " 'Pump Kick Mode',\n",
       " 'operator specific',\n",
       " 'time',\n",
       " 'Pump Kick Time',\n",
       " 'Pump Kick Time Di',\n",
       " 'pump kick',\n",
       " 'property',\n",
       " 'absolute time',\n",
       " 'Pump Kick Mode',\n",
       " 'operator specific',\n",
       " 'time',\n",
       " 'Pump Kick Time',\n",
       " 'Pump Kick Time Di',\n",
       " 'property',\n",
       " 'pump kick mode',\n",
       " 'pump',\n",
       " 'attribute',\n",
       " 'accessory liquid',\n",
       " 'buffer fluid',\n",
       " 'operating fluid',\n",
       " 'attribute',\n",
       " 'pump',\n",
       " 'generator',\n",
       " 'in flow',\n",
       " 'attribute',\n",
       " 'generic operation problem',\n",
       " 'attribute',\n",
       " 'problem',\n",
       " 'coolant flow',\n",
       " 'attribute',\n",
       " 'time',\n",
       " 'pump operation',\n",
       " 'attribute',\n",
       " 'partial load',\n",
       " 'attribute',\n",
       " 'problem',\n",
       " 'access',\n",
       " 'liquid flow',\n",
       " 'buffer fluid flow',\n",
       " 'operating fluid flow',\n",
       " 'attribute',\n",
       " 'pump',\n",
       " 'turbine',\n",
       " 'reverse flow',\n",
       " 'attribute',\n",
       " 'humidity',\n",
       " 'motor',\n",
       " 'attribute',\n",
       " 'dirty impeller',\n",
       " 'attribute',\n",
       " 'over load',\n",
       " 'attribute',\n",
       " 'coolant',\n",
       " 'high',\n",
       " 'limited',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'attribute',\n",
       " 'leakage problem',\n",
       " 'leakage',\n",
       " 'mechanical seal',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'controller',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'coolant liquid',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'attribute',\n",
       " 'failure',\n",
       " 'temperature management system',\n",
       " 'attribute',\n",
       " 'deceleration',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'access liquid',\n",
       " 'buffer fluid',\n",
       " 'operating fluid',\n",
       " 'attribute',\n",
       " 'limitation problem',\n",
       " 'attribute',\n",
       " 'ambient temperature',\n",
       " 'attribute',\n",
       " 'wear reserve',\n",
       " 'pump',\n",
       " 'exhausted',\n",
       " 'attribute',\n",
       " 'number',\n",
       " 'pump start cycles',\n",
       " 'timespan',\n",
       " 'property',\n",
       " 'overheating',\n",
       " 'converter',\n",
       " 'attribute',\n",
       " 'coolant',\n",
       " 'low limited',\n",
       " 'attribute',\n",
       " 'pump',\n",
       " 'normal speed',\n",
       " 'attribute',\n",
       " 'overheating',\n",
       " 'case',\n",
       " 'attribute',\n",
       " 'synchronization problem',\n",
       " 'attribute',\n",
       " 'limitation problem',\n",
       " 'attribute',\n",
       " 'generic temperature problem',\n",
       " 'attribute',\n",
       " 'problem',\n",
       " 'lubricant',\n",
       " 'attribute',\n",
       " 'start up time out',\n",
       " 'attribute',\n",
       " 'accessory liquid',\n",
       " 'buffer fluid',\n",
       " 'operating fluid',\n",
       " 'attribute',\n",
       " 'pressure',\n",
       " 'access',\n",
       " 'liquid',\n",
       " 'buffer fluid pressure',\n",
       " 'operating fluid pressure',\n",
       " 'attribute',\n",
       " 'number',\n",
       " 'pump start cycles',\n",
       " 'attribute',\n",
       " 'pump',\n",
       " 'normal speed',\n",
       " 'Residual',\n",
       " 'axial thrust',\n",
       " 'pump rotor',\n",
       " 'thrust - bearing selection',\n",
       " 'Greatest radial load',\n",
       " 'pump rotor',\n",
       " 'pump',\n",
       " 'condition',\n",
       " 'allow operating range',\n",
       " 'ambient temperature',\n",
       " 'equipment',\n",
       " 'part',\n",
       " 'term',\n",
       " 'suitable',\n",
       " 'Weblink',\n",
       " 'relationship',\n",
       " 'net positive suction head available',\n",
       " 'rate of flow',\n",
       " 'operating conditions',\n",
       " 'liquid',\n",
       " 'Rate of flow',\n",
       " 'balance device',\n",
       " 'Pump power',\n",
       " 'rate of flow',\n",
       " 'Speed',\n",
       " 'pump speed',\n",
       " 'flow rate',\n",
       " 'impeller eye',\n",
       " 'total flow',\n",
       " 'single - flow impeller',\n",
       " 'half flow',\n",
       " 'double - flow impeller',\n",
       " 'efficiency point',\n",
       " 'head per stage',\n",
       " 'maximum impeller',\n",
       " 'best efficiency point',\n",
       " 'Speed',\n",
       " 'cavitation performance',\n",
       " 'speed optimum rate of flow',\n",
       " 'impeller eye',\n",
       " 'NPSH3',\n",
       " 'first stage',\n",
       " 'maximum impeller',\n",
       " 'Pump power input',\n",
       " 'zero rate of flow',\n",
       " 'Pure number',\n",
       " 'point',\n",
       " 'ambient temperature',\n",
       " 'equipment',\n",
       " 'part',\n",
       " 'term',\n",
       " 'suitable',\n",
       " 'Displacement volume',\n",
       " 'one stroke',\n",
       " 'one cycle',\n",
       " 'Rotor resonant frequency',\n",
       " 'support',\n",
       " 'damping',\n",
       " 'action',\n",
       " 'pumped fluid',\n",
       " 'rotor',\n",
       " 'Greatest value',\n",
       " 'residual',\n",
       " 'axial thrust',\n",
       " 'pump rotor',\n",
       " 'pump',\n",
       " 'condition',\n",
       " 'allow operating range',\n",
       " 'relative humidity',\n",
       " 'equipment',\n",
       " 'part',\n",
       " 'term',\n",
       " 'suitable',\n",
       " 'continuous temperature',\n",
       " 'equipment',\n",
       " 'part',\n",
       " 'term',\n",
       " 'suitable',\n",
       " 'operating fluid',\n",
       " 'operating pressure',\n",
       " 'Control modes',\n",
       " 'manufacturer',\n",
       " 'product',\n",
       " 'logarithm',\n",
       " 'base 1',\n",
       " 'ratio',\n",
       " 'sound power',\n",
       " 'source P',\n",
       " 'reference value P',\n",
       " 'decibels',\n",
       " 'blowing agent',\n",
       " 'warm - up time',\n",
       " 'time',\n",
       " 'boiling vessel',\n",
       " 'working temperature',\n",
       " 'initial temperature',\n",
       " 'ambient temperature',\n",
       " 'equal',\n",
       " 'temperature',\n",
       " 'vacuum pump',\n",
       " 'atmospheric air',\n",
       " 'risk',\n",
       " 'Pump type',\n",
       " 'functional principle',\n",
       " 'pumped fluid',\n",
       " 'Integral',\n",
       " 'sound power',\n",
       " 'time interval',\n",
       " 'duration T',\n",
       " 'at t1',\n",
       " 'Volume flow rate',\n",
       " 'standard reference conditions',\n",
       " '°C',\n",
       " 'Device category',\n",
       " 'explosion protection',\n",
       " 'EU ATEX',\n",
       " 'speed',\n",
       " 'continuous operation',\n",
       " 'manufacturer',\n",
       " 'status',\n",
       " 'rotation',\n",
       " 'pump',\n",
       " 'Direction of rotation',\n",
       " 'shaft direction',\n",
       " 'drive end',\n",
       " 'shaft',\n",
       " 'clockwise',\n",
       " 'anticlock',\n",
       " 'Weblink',\n",
       " 'relationship',\n",
       " 'pump efficiency',\n",
       " 'rate of flow',\n",
       " 'operating conditions',\n",
       " 'speed',\n",
       " 'liquid',\n",
       " 'flow',\n",
       " 'pump',\n",
       " 'operation',\n",
       " 'temperature rise',\n",
       " 'pumped liquid',\n",
       " 'Rate of flow',\n",
       " 'point',\n",
       " 'Weblink',\n",
       " 'pump H Q ) curve',\n",
       " 'head',\n",
       " 'shut - off head',\n",
       " 'coincidental',\n",
       " 'total head decline',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c91393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17533"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_objects = list(set(all_objects))\n",
    "len(unique_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618a93e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captured',\n",
       " 'Numero link E1 interfaccia Ater',\n",
       " 'je m²',\n",
       " 'manovra a mano',\n",
       " 'effettuazione misure ”',\n",
       " 'PSSC',\n",
       " 'Kan også være romlefelt f eks',\n",
       " 'Betonwerkstein nach DIN 18333',\n",
       " 'angrenzt bzw',\n",
       " 'EN 12467 Faserzement - Tafeln - Produktspezifikation und']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(unique_objects, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1941b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37d27509",
   "metadata": {},
   "source": [
    "### We want only english, but bsdd doesn't really help us there... too much random language stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a62bd1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenations = []\n",
    "for name, description in zip(to_be_parsed.name, to_be_parsed.description):\n",
    "    new_str = str(name) + \" \" + str(description)\n",
    "    concatenations.append(new_str.encode(\"ascii\", \"ignore\").decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cc85adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ratanumero Ratanumero jolla kohde sijaitsee',\n",
       " 'Omistaja Kohteen omistaja',\n",
       " 'Nimi Kohteen nimi',\n",
       " 'Kiinnitys Kohteen, rakenteen tai laitteen kiinnitys',\n",
       " 'Pohjaimen luokittelu Pohjaimen jykkyys',\n",
       " 'Materiaali Kohteen, rakenteen tai laitteen materiaali.',\n",
       " 'Kaari / suora /siirtymkaari Tieto sijaitseeko kisko kaarella, suoralla vai siirtymkaarella',\n",
       " 'Kiskotusvuosi New property description 2',\n",
       " 'Uusi / kierrtetty Tieto onko kisko uusi vai kierrtetty',\n",
       " 'Rataplkkyjako RATO 11:n mukainen plkkyjako',\n",
       " 'Puuplkyn kyllstys Tieto siit onko puuplkky kyllstetty vai ei']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenations[124:135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c984839b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2185430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec30b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9845c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-enlishg stufff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1e5a5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aaadfeff83343788789c4a76936a8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53dd2470e504fbe847b9e0270b29fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac65db75ee04ec69a67fad5654953b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1806ec24f6854d598e576d37f880570b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7ebabd895643aa815cfbae2ff820bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2448df5dd49d4e21bac914212a3ef13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddf7177d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m languages \u001b[38;5;241m=\u001b[39m [predicted[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m predicted \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenations\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/base.py:1101\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1098\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1099\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1100\u001b[0m     )\n\u001b[0;32m-> 1101\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1025\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1026\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:1226\u001b[0m, in \u001b[0;36mXLMRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1226\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1238\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:854\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    845\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    847\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    848\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    849\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    867\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:528\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    519\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    520\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    521\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    526\u001b[0m     )\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 528\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:454\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    452\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 454\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:466\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 466\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:364\u001b[0m, in \u001b[0;36mXLMRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 364\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "languages = [predicted['label'] for predicted in pipe(concatenations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2796ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb7b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e94aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8094ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-english rows\n",
    "for index, row in to_be_parsed.iterrows():\n",
    "    language = languages[index]\n",
    "    if  language != 'en':\n",
    "        to_be_parsed.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f051ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6106814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5637d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3abb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c07be92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a graph quickly\n",
    "from rdflib import URIRef, BNode, Literal, Namespace, Graph\n",
    "from rdflib.namespace import XSD, RDF, RDFS, SKOS, NamespaceManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a8ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_output_fp = Path.cwd().joinpath(\"data\", \"graph_output\")\n",
    "graph_output_fp.mkdir(parents=True, exist_ok=True) # create directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3774a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BSDD = Namespace(\"http://bsdd.buildingsmart.org/def#\") # https://identifier.buildingsmart.org/uri/\n",
    "EX = Namespace(\"http://ex.ample.org/span/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7f397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0ee6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_triples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c3650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for span_idx, span in enumerate(unique_objects):\n",
    "    object_triple = (EX[str(span_idx)], RDFS.label,  Literal(span, lang='en'))\n",
    "    all_triples.append(object_triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ceb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = to_be_parsed.subject\n",
    "bsdd_names = to_be_parsed.name\n",
    "bsdd_descriptions = to_be_parsed.description\n",
    "objects_counts = to_be_parsed.objects_and_counts\n",
    "\n",
    "\n",
    "for uid, name, description, objects_counts in zip(uids, bsdd_names, bsdd_descriptions, objects_counts):\n",
    "    \n",
    "    name_triple = (URIRef(uid), RDFS.label,  Literal(name, lang='en'))\n",
    "    description_triple= (URIRef(uid), SKOS.definition,  Literal(description, lang='en'))\n",
    "    all_triples += [name_triple, description_triple]\n",
    "    \n",
    "    if type(objects_counts) == str:\n",
    "        objects = parse_objects(objects_counts)\n",
    "    else:\n",
    "        objects = [o for o, c in objects_counts]\n",
    "        \n",
    "    for span in objects:\n",
    "        span_idx = unique_objects.index(span)\n",
    "        association_triple = (URIRef(uid), EX.associatedSpan, EX[str(span_idx)])\n",
    "        all_triples.append(association_triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02257d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "issues = []\n",
    "for t in all_triples:\n",
    "    assert len(t) == 3\n",
    "    if t not in graph:\n",
    "        try:\n",
    "            graph.add(t)\n",
    "        except:\n",
    "            issues.append(f\"issue @ {t}\")\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf2dfceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "480a4e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b520d700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Neea29be65b5c4d6cb92d4ee22513ebfe (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.serialize(destination=graph_output_fp.joinpath(\"test_graph.ttl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf43935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12642060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbf9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c285e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done ish; \n",
    "# - for each row in the dataframe, predict the language. input could be concatenation of (name + description)\n",
    "# - get only those rows that have english as the predicted language\n",
    "# - create a graph with:\n",
    "# -- all bsdd terms with (uid bsdd:name name; bsdd:descripition description. )\n",
    "# -- all object nodes with (listIDX bsdd:name string)\n",
    "# -- all relations between terms and objects (uid meta:obj_found listIDX)\n",
    "# - upload to graphDB and prepare sparql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8edfa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers.util import pytorch_cos_sim\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7fe8489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"query MyQuery {\n",
    "  classification(\n",
    "    limit: \"20\"\n",
    "    where: {domain: {name: {EQ: \"CCI Construction\"}}}\n",
    "  ) {\n",
    "    id\n",
    "    name\n",
    "    definition\n",
    "    synonym\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "url = 'https://bsdd.ontotext.com/graphql/'\n",
    "r_test = requests.post(url, json={'query': query})\n",
    "print(r_test.status_code)\n",
    "\n",
    "json_data_test = json.loads(r_test.text)\n",
    "\n",
    "\n",
    "\n",
    "query = \"\"\"query MyQuery {\n",
    "  classification(\n",
    "    limit: \"10000\"\n",
    "    where: {domain: {name: {EQ: \"IFC\"}}}\n",
    "  ) {\n",
    "    id\n",
    "    name\n",
    "    definition\n",
    "    synonym\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "url = 'https://bsdd.ontotext.com/graphql/'\n",
    "r = requests.post(url, json={'query': query})\n",
    "print(r.status_code)\n",
    "\n",
    "json_data = json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2bb8ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list_test = []\n",
    "id_list_test = []\n",
    "for item in json_data_test['data']['classification']:\n",
    "\n",
    "  if item['name'] and item['definition'] is not None:\n",
    "    concatenated_string = item['name'] + '. ' + item['definition']\n",
    "  elif item['name'] is None:\n",
    "    concatenated_string = item['definition']\n",
    "  elif item['definition'] is None:\n",
    "    concatenated_string = item['name']\n",
    "  id_list_test.append(item['id'])\n",
    "\n",
    "  result_list_test.append(concatenated_string)\n",
    "\n",
    "result_list = []\n",
    "id_list = []\n",
    "for item in json_data['data']['classification']:\n",
    "  if item['name'] and item['definition'] is not None:\n",
    "    concatenated_string = item['name'] + '. ' + item['definition']\n",
    "  elif item['name'] is None:\n",
    "    concatenated_string = item['definition']\n",
    "  elif item['definition'] is None:\n",
    "    concatenated_string = item['name']\n",
    "  id_list.append(item['id'])\n",
    "\n",
    "  result_list.append(concatenated_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2bec5601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e0123b70ec4a408c28d7f46d31a136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb475375695b48b886bd6b17b85e4025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cd5c1ac9f74b359130b3b9f559f133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312409f0d01e41fa99e04eb49cd837ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bde675cd8ff424b90237f4fdfd0b5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc98de97d63948aaabf67a5b74892637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6fd69766484a46861e1579ea24accb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a316b91acdd43be9906bf3efadd6e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8cf4cf3e474c58a0af8f8a12255c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afc0ddc3f044a06859ea93eb7052fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deccb081aad48dbb0ec251c2725428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07290b88f73642f296f16e6107147d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7ef93e0b4d46a79ebcda3d3a2de2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb750b6bc394f49839e26f4db673aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "show_progress_bar = True\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ba2b902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ec2144abb04109801e34e0fe81cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m embeddings_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(result_list_test, show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: output_tokens, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:554\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    549\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[1;32m    550\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    551\u001b[0m     embedding_output,\n\u001b[1;32m    552\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    553\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m--> 554\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    555\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    556\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    559\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:340\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    337\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    339\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m--> 340\u001b[0m     hidden_states,\n\u001b[1;32m    341\u001b[0m     attention_mask,\n\u001b[1;32m    342\u001b[0m     head_mask[i],\n\u001b[1;32m    343\u001b[0m     position_bias,\n\u001b[1;32m    344\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    347\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:309\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m    308\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 309\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    310\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:263\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    262\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 263\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/modules/linear.py:94\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/irec/lib/python3.9/site-packages/torch/nn/functional.py:1753\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(result_list, show_progress_bar=show_progress_bar, batch_size=batch_size, convert_to_tensor=True)\n",
    "embeddings_test = model.encode(result_list_test, show_progress_bar=show_progress_bar, batch_size=batch_size, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be40e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_list = []\n",
    "i = 0\n",
    "for key in embeddings_test:\n",
    "\n",
    "  cos_score = pytorch_cos_sim(key, embeddings)\n",
    "  cos_value, cos_index = torch.topk(cos_score,5,1)\n",
    "  indices_list = cos_index.flatten().tolist()\n",
    "  value_list = cos_value.flatten().tolist()\n",
    "  diff = value_list[0] - value_list[4]\n",
    "  #print(diff)\n",
    "  \n",
    "  if diff > 0.06:\n",
    "    triple = []\n",
    "    triple.append(id_list_test[i])\n",
    "    triple.append('similar')\n",
    "    triple.append(id_list[indices_list[0]])\n",
    "    triple_list.append(triple)\n",
    "  i = i+1\n",
    "print(triple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05797232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941b7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382f678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46169c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203fd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphDB SPARQL QUERY\n",
    "\"\"\"\n",
    "prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "prefix bsdd:<http://bsdd.buildingsmart.org/def#>\n",
    "prefix skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "prefix ex: <http://ex.ample.org/span/>\n",
    "\n",
    "SELECT DISTINCT ?subject ?subj_def ?object ?obj_def (COUNT(?definition_node) AS ?shared_def_terms) (SUM(?generic) as ?total_g)\n",
    "WHERE {\n",
    "    ?subject_node ex:associatedSpan ?definition_node ;\n",
    "                  skos:definition ?subj_def ;\n",
    "                  rdfs:label ?subject .\n",
    "    {   # sub query to check how generic the definition_node is (number of edges)\n",
    "        SELECT DISTINCT ?definition_node (COUNT(?defined_node) AS ?generic) \n",
    "        WHERE{\n",
    "            ?definition_node  ^ex:associatedSpan ?defined_node .\n",
    "        } \n",
    "        GROUP BY ?definition_node\n",
    "        HAVING (?generic < 30)  # each shared term has less than 20 edges generic\n",
    "    }\n",
    "    ?object_node ex:associatedSpan ?definition_node ;\n",
    "                 skos:definition ?obj_def;\n",
    "                 rdfs:label ?object .\n",
    "\n",
    "    FILTER (str(?subject) != str(?object))\n",
    "    # ensure same ordering of subject object so we don't get reverse triples\n",
    "    FILTER (STR(?object) < STR(?subject))\n",
    "}\n",
    "GROUP BY ?subject ?object ?subj_def ?obj_def\n",
    "# at least 3 shared terms, that together have more than 10 edges and less than 300 in total\n",
    "HAVING (?shared_def_terms > 2 && ?total_g > 10 && ?total_g < 300)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
