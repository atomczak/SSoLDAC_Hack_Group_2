{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843333e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Any, Optional, Dict\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "\n",
    "from utilities import cleaning_utils\n",
    "from utilities.spar_utils import NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8b906",
   "metadata": {},
   "source": [
    "### Set up Named Entity Recognition (NER) \n",
    "We'll use: \n",
    "* TextBlob (NLTK's implementation of punkttokenizer under the hood) to split into sentences.\n",
    "* SPaR.txt to predict which objects occur, some cleaning on top of this. \n",
    "  * We'll assume you have docker installed on your machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a41875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download SPaR.txt if required\n",
    "from pathlib import Path\n",
    "spartxt_path = Path(\"SPaR.txt/\")\n",
    "if not spartxt_path.exists():\n",
    "    !git clone https://github.com/rubenkruiper/SPaR.txt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4dd52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPaR_API\r\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    ### Start our `SPaR_API` container if it exists\n",
    "    !docker start SPaR_API\n",
    "except:\n",
    "    ### Else, set up the `SPaR_API` container\n",
    "    # build the SPaR.txt image, call it `spar`\n",
    "    !docker build -t spar SPaR.txt/.\n",
    "    # Run the image called `spar` in a container that we will call `SPaR_API`, with the API port at localhost:8501\n",
    "    # NOTE: this will train a SPaR.txt model locally, which takes about 20 minutes on a CPU \n",
    "    !docker run --name SPaR_API -p 8501:8501 spar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70da68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_api = \"http://localhost:8501/predict_objects/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3bf80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': {'obj': ['Thermoplastic materials',\n",
       "   'ceilings',\n",
       "   'rooflights',\n",
       "   'lighting diffusers',\n",
       "   'a hazard',\n",
       "   'a fire']},\n",
       " 'num_input_tokens': 26,\n",
       " 'num_output_tokens': 17}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"Thermoplastic materials in ceilings, rooflights and lighting diffusers provide a significant hazard in a fire.\"\n",
    "response = requests.post(ner_api,  json={\"sentence\": example}).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9a0fd",
   "metadata": {},
   "source": [
    "### Parsing an example IFC class and description\n",
    "* source: https://search-test.bsdd.buildingsmart.org/uri/buildingsmart/ifc-4.3/class/IfcWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3ee22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"IfcWindow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9042d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "The window is a building element that is predominately used to provide natural light and fresh air. \n",
    "It includes vertical opening but also horizontal opening such as skylights or light domes. \n",
    "It includes constructions with swinging, pivoting, sliding, or revolving panels and fixed panels. \n",
    "A window consists of a lining and one or several panels. \n",
    "A window can:be a \"free standing\" window, contained in an IfcSpatialElement such as an IfcBuildingStorey. \n",
    "fill an opening, typically in a wall. \n",
    "The window will then have a FillsVoids attribute which uses the IfcRelFillsElement relationship to relate the IfcWindow with the IfcOpeningElement; \n",
    "be part of an element assembly, typically an IfcCurtainWall. \n",
    "The window will then have a Decomposes attribute which uses the the IfcRelAggregates relationship to relate the window with the assembly of elements;\n",
    "There are two main representations for window occurrences:\n",
    "IfcWindow entities that have a 3D rectangle 'Profile' shape representation defined. \n",
    "This profile can then be used to parametrically generate the geometry of a window. \n",
    "If not provided, the profile of the IfcOpeningElement can be used if the window fills an opening. \n",
    "The parameters are specified on the relating IfcWindowType that references IfcWindowLiningProperties and \n",
    "IfcWindowPanelProperties for each panel in the window; \n",
    "IfcWindow entities that are not parametrically generated and have only 'Brep', or 'SurfaceModel' geometry.\n",
    "In addition, an IfcWindow may commonly include a 'FootPrint' representation defining the 2D shape of the window and its swing.\n",
    "the window width and height the window opening direction (by the positive y-axis of the ObjectPlacement)\n",
    "The IfcWindowType specifies parameters which are common to all of its occurrences of IfcWindow:\n",
    "the partitioning type (single panel, double panel, tripel panel, more panels) the operation type \n",
    "(swing, tilt and turn, pivot revolve, fixed casement, etc.) \n",
    "the window panel hinge side (by using two different styles for right and left opening windows) \n",
    "the particular attributes for the lining by the IfcWindowLiningProperties the particular attributes \n",
    "for the panels by the  IfcWindowPanelPropertiesREFERENCE Definition according to ISO 6707-1 Construction \n",
    "for closing a vertical or near vertical opening in a wall or pitched roof that will admit light and \n",
    "may admit fresh air. NOTE The entity IfcWindowStandardCase has been deleted. Use an IfcWindow with \n",
    "a 'Profile' representation instead. The IfcWindow should also have an IfcWindowType with \n",
    "ParameterTakesPrecedence set to 'TRUE'. IFC4 CHANGE The attributes PredefinedType and OperationType are\n",
    "added, the applicable type object has been changed to IfcWindowType. HISTORY New entity in IFC1.0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae331ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The window is a building element that is predominately used to provide natural light and fresh air.',\n",
       " 'It includes vertical opening but also horizontal opening such as skylights or light domes.',\n",
       " 'It includes constructions with swinging, pivoting, sliding, or revolving panels and fixed panels.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = NER(ner_api)\n",
    "ner.split_into_sentences(to_be_split=description)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1080102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an opening',\n",
       " 'fixed casement',\n",
       " 'HISTORY New entity',\n",
       " 'more panels',\n",
       " 'The parameters']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ner_output = ner.process_text(description)\n",
    "random.sample(raw_ner_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f66c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic cleaning for the entire set of extracted objects\n",
    "regex_filter = cleaning_utils.RegexFilter()\n",
    "def basic_cleaning(to_be_cleaned):\n",
    "    # some basic cleaning steps\n",
    "    _, regex_cleaned  = regex_filter.run_filter(to_be_cleaned) # _ would be the list of terms removed by our regex filters\n",
    "    basic_cleaned = cleaning_utils.custom_cleaning_rules(regex_cleaned)\n",
    "    determiners_removed = [cleaning_utils.remove_determiners(t) for t in basic_cleaned]\n",
    "    cleaned_terms = [t for t in determiners_removed if t]\n",
    "    cleaned_counter = Counter(cleaned_terms)\n",
    "    return cleaned_terms, cleaned_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81535da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOTE The entity IfcWindowStandardCase',\n",
       " 'tilt',\n",
       " 'panels',\n",
       " 'pitched roof',\n",
       " 'IfcWindowLiningProperties']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ner_output, terms_with_counts = basic_cleaning(raw_ner_output)\n",
    "random.sample(cleaned_ner_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec0ef0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another, smaller example\n",
    "label = \"abrasion\"\n",
    "description = \"\"\"wearing or grinding away of material by friction; usually caused by sand, gravel, or stones, carried by wind or water\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be88a5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wearing',\n",
       " 'material',\n",
       " 'friction',\n",
       " 'sand',\n",
       " 'gravel',\n",
       " 'stones',\n",
       " 'wind',\n",
       " 'water']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ner_output = ner.process_text(description)\n",
    "cleaned_ner_output, terms_with_counts = basic_cleaning(raw_ner_output)\n",
    "cleaned_ner_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12c291",
   "metadata": {},
   "source": [
    "### First, remove all non-English rows from the bSDD extract\n",
    "* We'll use an existing pretrained language predictor `papluca/xlm-roberta-base-language-detection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd0407cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the language classifier\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "def228f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(some_list: List, chunk_size: int=8) -> List[List]:\n",
    "    \"\"\"\n",
    "    Helper function to split a list into smaller lists of a given size.\n",
    "\n",
    "    :param some_list:   List that has to be split into chunks.\n",
    "    :param chunk_size:  Size of the sublists that will be returned.\n",
    "    :return list_of_sublists:  A list of sublists, each with a maximum size of `chunk_size`.\n",
    "    \"\"\"\n",
    "    return [some_list[i:i + chunk_size] for i in range(0, len(some_list), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01c142b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and output csv for the language detection\n",
    "unprocessed_csv = Path(\"data\", \"bsdd_descriptions.csv\")\n",
    "english_csv = Path(\"data\", \"bsdd_descriptions_english.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9927cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we'll drop non-english lines, based on  \n",
    "if not english_csv.exists():\n",
    "    bsdd_df = pd.read_csv(unprocessed_csv)\n",
    "    \n",
    "    # combine name and description to determine language\n",
    "    concatenations = []\n",
    "    for name, description in zip(bsdd_df.name, bsdd_df.description):\n",
    "        new_str = str(name) + \" \" + str(description)\n",
    "        concatenations.append(new_str.encode(\"ascii\", \"ignore\").decode())\n",
    "        \n",
    "    # reduce processing time a little by considering unique values only (many duplicates in bSDD)\n",
    "    batch_size = 8 # not sure what is the expected batchsize for the language prediction model\n",
    "    unique_concatenations = list(set(concatenations))\n",
    "    languages = []\n",
    "    subsets_of_unique_concatenations = split_list(unique_concatenations, batch_size)\n",
    "    print(f\"Predicting languages for unique concatenations of name and description, batch size {batch_size}\")\n",
    "    for subset in tqdm(subsets_of_unique_concatenations):\n",
    "        languages += [predicted['label'] for predicted in pipe(subset)]\n",
    "    \n",
    "    language_lookup = {k:v for k, v in zip(unique_concatenations, languages)}\n",
    "    \n",
    "    # drop the non-english rows in the dataframe\n",
    "    for idx, row in bsdd_df.iterrows():\n",
    "        key = str(row[\"name\"]) + \" \" + str(row[\"description\"])\n",
    "        language = language_lookup[key.encode(\"ascii\", \"ignore\").decode()]\n",
    "        print(idx, language)\n",
    "        if language != 'en':\n",
    "            bsdd_df.drop(idx, inplace=True) \n",
    "        \n",
    "    bsdd_df.to_csv(english_csv)\n",
    "else:\n",
    "    bsdd_df = pd.read_csv(english_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c4753e",
   "metadata": {},
   "source": [
    "### Process all descriptions in our bSDD extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61cf52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_csv = Path(\"data\", \"bsdd_descriptions_english.csv\")\n",
    "processed_csv = Path(\"data\", \"bsdd_parsed_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f20db642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3604/3604 [06:58<00:00,  8.62it/s]\n"
     ]
    }
   ],
   "source": [
    "if not processed_csv.exists():\n",
    "    bsdd_df = pd.read_csv(english_csv)\n",
    "    \n",
    "    # process all of the descriptions with SPaR.txt \n",
    "    # we'll process the unique description, since there is a lot of overlap in bSDD\n",
    "    unique_descriptions = list(set(bsdd_df.description))\n",
    "    unique_predictions_raw = []\n",
    "    print(f\"Predicting terms found in {len(unique_descriptions)} unique descriptions\")\n",
    "    for description in tqdm(unique_descriptions):\n",
    "        try:\n",
    "            unique_predictions_raw.append(ner.process_text(description))\n",
    "        except:\n",
    "            unique_predictions_raw.append([])\n",
    "    \n",
    "    # We'll do some cleaning of terms, count-based as well\n",
    "    cleaned_object_lists, subset_counts = zip(*[basic_cleaning(sublist) for sublist in unique_predictions_raw])\n",
    "    \n",
    "    # Count-based cleaning (only consider objects that occur at least X times in all descriptions)\n",
    "    cleaned_counter = sum(subset_counts, Counter())\n",
    "    cleaned_object_lists = [[t for t in terms if cleaned_counter[t] >= 3] for terms in cleaned_object_lists]\n",
    "    \n",
    "    # update the dataframe and save to csv \n",
    "    objects_column = [''] * len(bsdd_df.description)\n",
    "    for description, cleaned_prediction in zip(unique_descriptions, cleaned_object_lists):\n",
    "        indices = bsdd_df.index[bsdd_df.description==description].tolist()\n",
    "        for idx in indices:\n",
    "            objects_column[idx] = \", \".join(cleaned_prediction)\n",
    "            \n",
    "    bsdd_df[\"description_NER\"] = objects_column\n",
    "    bsdd_df.to_csv(processed_csv)\n",
    "else:\n",
    "    bsdd_df = pd.read_csv(processed_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d148de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject</th>\n",
       "      <th>name</th>\n",
       "      <th>uid</th>\n",
       "      <th>description</th>\n",
       "      <th>description_NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/FTIA/...</td>\n",
       "      <td>Location track</td>\n",
       "      <td>LocationTrack</td>\n",
       "      <td>Location track number or name as an abbreviation</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/FTIA/...</td>\n",
       "      <td>Additional details</td>\n",
       "      <td>AdditionalDetails</td>\n",
       "      <td>E.g. additional information related to install...</td>\n",
       "      <td>information, installation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/FTIA/...</td>\n",
       "      <td>Post height</td>\n",
       "      <td>PostHeight</td>\n",
       "      <td>Height of the post in millimeters if sign has ...</td>\n",
       "      <td>Height, millimeters, sign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/FTIA/...</td>\n",
       "      <td>Installation direction</td>\n",
       "      <td>InstallationDirection</td>\n",
       "      <td>Installation direction of the sign</td>\n",
       "      <td>sign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/FTIA/...</td>\n",
       "      <td>Route number</td>\n",
       "      <td>RouteNumber</td>\n",
       "      <td>The route number on which the object is located</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12525</th>\n",
       "      <td>27864</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/NVDB/...</td>\n",
       "      <td>DiameterYtre_9729</td>\n",
       "      <td>DiameterYtre_9729</td>\n",
       "      <td>Angir ytre diameter for trekkekum.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>27939</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/NVDB/...</td>\n",
       "      <td>Materialtype_10429</td>\n",
       "      <td>Materialtype_10429</td>\n",
       "      <td>Angir type materiale.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12527</th>\n",
       "      <td>27979</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/NVDB/...</td>\n",
       "      <td>Materialtype_9388</td>\n",
       "      <td>Materialtype_9388</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>28080</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/NVDB/...</td>\n",
       "      <td>Spenning_10049</td>\n",
       "      <td>Spenning_10049</td>\n",
       "      <td>Angir spenningen som leveres ut fra enheten.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12529</th>\n",
       "      <td>28082</td>\n",
       "      <td>https://identifier.buildingsmart.org/uri/NVDB/...</td>\n",
       "      <td>Kapasitet_10043</td>\n",
       "      <td>Kapasitet_10043</td>\n",
       "      <td>Angir totalt kapasitet for alle batterier.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12530 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            subject  \\\n",
       "0               0  https://identifier.buildingsmart.org/uri/FTIA/...   \n",
       "1               1  https://identifier.buildingsmart.org/uri/FTIA/...   \n",
       "2               2  https://identifier.buildingsmart.org/uri/FTIA/...   \n",
       "3               3  https://identifier.buildingsmart.org/uri/FTIA/...   \n",
       "4               4  https://identifier.buildingsmart.org/uri/FTIA/...   \n",
       "...           ...                                                ...   \n",
       "12525       27864  https://identifier.buildingsmart.org/uri/NVDB/...   \n",
       "12526       27939  https://identifier.buildingsmart.org/uri/NVDB/...   \n",
       "12527       27979  https://identifier.buildingsmart.org/uri/NVDB/...   \n",
       "12528       28080  https://identifier.buildingsmart.org/uri/NVDB/...   \n",
       "12529       28082  https://identifier.buildingsmart.org/uri/NVDB/...   \n",
       "\n",
       "                         name                    uid  \\\n",
       "0              Location track          LocationTrack   \n",
       "1          Additional details      AdditionalDetails   \n",
       "2                 Post height             PostHeight   \n",
       "3      Installation direction  InstallationDirection   \n",
       "4                Route number            RouteNumber   \n",
       "...                       ...                    ...   \n",
       "12525       DiameterYtre_9729      DiameterYtre_9729   \n",
       "12526      Materialtype_10429     Materialtype_10429   \n",
       "12527       Materialtype_9388      Materialtype_9388   \n",
       "12528          Spenning_10049         Spenning_10049   \n",
       "12529         Kapasitet_10043        Kapasitet_10043   \n",
       "\n",
       "                                             description  \\\n",
       "0      Location track number or name as an abbreviation    \n",
       "1      E.g. additional information related to install...   \n",
       "2      Height of the post in millimeters if sign has ...   \n",
       "3                     Installation direction of the sign   \n",
       "4        The route number on which the object is located   \n",
       "...                                                  ...   \n",
       "12525                 Angir ytre diameter for trekkekum.   \n",
       "12526                              Angir type materiale.   \n",
       "12527                                                  .   \n",
       "12528       Angir spenningen som leveres ut fra enheten.   \n",
       "12529         Angir totalt kapasitet for alle batterier.   \n",
       "\n",
       "                 description_NER  \n",
       "0                                 \n",
       "1      information, installation  \n",
       "2      Height, millimeters, sign  \n",
       "3                           sign  \n",
       "4                         object  \n",
       "...                          ...  \n",
       "12525                             \n",
       "12526                             \n",
       "12527                             \n",
       "12528                             \n",
       "12529                             \n",
       "\n",
       "[12530 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the DataFrame, should be only/mostly english and have objects assigned that occur in the descriptions\n",
    "bsdd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98af9db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly grab all unique terms that we found in all of the descriptions\n",
    "all_objects = []\n",
    "for string_or_list in bsdd_df.description_NER:\n",
    "    all_objects += string_or_list.split(\", \")\n",
    "all_objects = list(set(all_objects))\n",
    "len(all_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4f70e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['performance',\n",
       " 'pedestal',\n",
       " 'OverallHeight',\n",
       " 'cross - section size',\n",
       " 'specification',\n",
       " 'operating fluid',\n",
       " 'reference line',\n",
       " 'IEC 60947 series',\n",
       " 'flange',\n",
       " 'continuously']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_objects, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e69eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows that don't have any objects in their description\n",
    "for idx, row in bsdd_df.iterrows():\n",
    "    if not row[\"description_NER\"]:\n",
    "        bsdd_df.drop(idx, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce2e3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv = Path(\"data\", \"bsdd_graph_input.csv\")\n",
    "bsdd_df.to_csv(final_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91a238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
